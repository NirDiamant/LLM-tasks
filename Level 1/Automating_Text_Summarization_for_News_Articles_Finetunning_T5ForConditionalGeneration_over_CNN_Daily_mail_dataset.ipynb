{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automating Text Summarization for News Articles - Finetunning T5ForConditionalGeneration over CNN Daily mail dataset"
      ],
      "metadata": {
        "id": "MYmFNwmmpDFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "tdMoXwdnmrOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rz4WXcemlul"
      },
      "outputs": [],
      "source": [
        "pip install torch pytorch-lightning transformers datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the Dataset"
      ],
      "metadata": {
        "id": "1fulAn4KmuVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
      ],
      "metadata": {
        "id": "DF0DtX1nmwQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Data Module"
      ],
      "metadata": {
        "id": "yjMgT_dVm0rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning import LightningDataModule\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "class SummarizationDataModule(LightningDataModule):\n",
        "    def __init__(self, dataset, tokenizer_name='t5-small', batch_size=4):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = self.dataset[\"train\"]\n",
        "        self.val_dataset = self.dataset[\"validation\"]\n",
        "        self.test_dataset = self.dataset[\"test\"]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        articles = [item['article'] for item in batch]\n",
        "        summaries = [item['highlights'] for item in batch]\n",
        "        encodings = self.tokenizer(articles, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        labels = self.tokenizer(summaries, max_length=150, truncation=True, padding=\"max_length\", return_tensors=\"pt\").input_ids\n",
        "        labels[labels == 0] = -100  # To ignore pad tokens in loss computation\n",
        "        return dict(input_ids=encodings.input_ids, attention_mask=encodings.attention_mask, labels=labels)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)"
      ],
      "metadata": {
        "id": "UFfKk0XXmv41"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model"
      ],
      "metadata": {
        "id": "0tw7OGnym7i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import LightningModule\n",
        "from transformers import T5ForConditionalGeneration, AdamW\n",
        "\n",
        "class NewsSummarizer(LightningModule):\n",
        "    def __init__(self, model_name='t5-small', learning_rate=2e-4):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        output = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        return output.loss, output.logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n",
        "        loss, _ = self(input_ids, attention_mask, labels)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n",
        "        loss, _ = self(input_ids, attention_mask, labels)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=self.learning_rate)\n"
      ],
      "metadata": {
        "id": "cbmMmmSRm8Jl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "I7VdR1HPnBO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "import torch\n",
        "\n",
        "data_module = SummarizationDataModule(dataset)\n",
        "model = NewsSummarizer()\n",
        "\n",
        "trainer = Trainer(max_epochs=3, devices=1 if torch.cuda.is_available() else 0, accelerator=\"gpu\")\n",
        "trainer.fit(model, datamodule=data_module)\n"
      ],
      "metadata": {
        "id": "bePDKMx9nByJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "LqquKsAynEtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(article, model, tokenizer, device='cuda'):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    inputs = tokenizer.encode(\"summarize: \" + article, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "    summary_ids = model.model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "article = \"Your new article text here.\"\n",
        "summary = generate_summary(article, model, data_module.tokenizer)\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "lGZYR53_nFQa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}